"""
Draft Storage
Manages scene briefs, drafts, reviews, and summaries.
"""

import shutil
from pathlib import Path
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple
import os

from app.config import config as app_cfg
from app.context.retriever import DynamicContextRetriever
from app.schemas.draft import ChapterSummary, Draft, ReviewResult, SceneBrief
from app.schemas.volume import VolumeSummary
from app.storage.base import BaseStorage
from app.storage.volumes import VolumeStorage
from app.utils.chapter_id import ChapterIDValidator, normalize_chapter_id

# Max number of previous-version backups to keep per chapter.
_storage_cfg = app_cfg.get("storage", {})
MAX_DRAFT_PREV_BACKUPS = int(_storage_cfg.get("max_draft_prev_backups", 3))


class DraftStorage(BaseStorage):
    """File-based draft storage."""

    def __init__(self, data_dir: Optional[str] = None):
        super().__init__(data_dir)
        self.context_retriever = DynamicContextRetriever(self)
        self.volume_storage = VolumeStorage(data_dir)

    def _canonicalize_chapter_id(self, chapter_id: str) -> str:
        normalized = normalize_chapter_id(chapter_id)
        if normalized and ChapterIDValidator.validate(normalized):
            return normalized
        return (str(chapter_id).strip() if chapter_id else "")

    def _resolve_chapter_dir_name(self, project_id: str, chapter: str) -> str:
        drafts_dir = self.get_project_path(project_id) / "drafts"
        canonical = self._canonicalize_chapter_id(chapter)
        if drafts_dir.exists():
            canonical_path = drafts_dir / canonical
            if canonical_path.exists():
                return canonical
            raw_path = drafts_dir / str(chapter)
            if raw_path.exists():
                return str(chapter)
            for path in drafts_dir.iterdir():
                if path.is_dir() and self._canonicalize_chapter_id(path.name) == canonical:
                    return path.name
        return canonical

    def get_chapter_draft_dir(self, project_id: str, chapter: str) -> Path:
        """Resolve the draft directory for a chapter.

        Args:
            project_id: Project id.
            chapter: Chapter id.

        Returns:
            Draft directory path.
        """
        resolved = self._resolve_chapter_dir_name(project_id, chapter)
        return self.get_project_path(project_id) / "drafts" / resolved

    def get_latest_draft_file(self, project_id: str, chapter: str) -> Optional[Path]:
        """Return the most recently modified draft file for a chapter.

        Args:
            project_id: Project id.
            chapter: Chapter id.

        Returns:
            Path to latest draft file if present.
        """
        draft_dir = self.get_chapter_draft_dir(project_id, chapter)
        if not draft_dir.exists():
            return None
        candidates = list(draft_dir.glob("draft_*.md"))
        final_path = draft_dir / "final.md"
        if final_path.exists():
            candidates.append(final_path)
        if not candidates:
            return None
        return max(candidates, key=lambda path: path.stat().st_mtime)

    def _final_paths(self, project_id: str, chapter: str) -> Tuple[Path, Path]:
        canonical = self._canonicalize_chapter_id(chapter)
        self._migrate_chapter_dir(project_id, chapter, canonical)
        chapter_dir = self.get_project_path(project_id) / "drafts" / canonical
        final_path = chapter_dir / "final.md"
        history_dir = chapter_dir / "history"
        return final_path, history_dir

    @staticmethod
    def _rotate_draft_history(final_path: Path, history_dir: Path) -> None:
        """Move current final.md into history/ with timestamp, prune old backups."""
        history_dir.mkdir(parents=True, exist_ok=True)
        ts = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%S")
        backup_name = f"final_{ts}.md"
        try:
            os.replace(str(final_path), str(history_dir / backup_name))
        except OSError:
            return

        backups = sorted(
            [p for p in history_dir.iterdir() if p.name.startswith("final_") and p.suffix == ".md"],
            key=lambda p: p.stat().st_mtime,
        )
        while len(backups) > MAX_DRAFT_PREV_BACKUPS:
            oldest = backups.pop(0)
            try:
                oldest.unlink()
            except OSError:
                pass

    async def save_current_draft(
        self,
        project_id: str,
        chapter: str,
        content: str,
        word_count: Optional[int] = None,
        pending_confirmations: Optional[List[str]] = None,
        create_prev_backup: bool = True,
    ) -> Draft:
        """Save the current draft (single-version) to final.md.

        设计目标：
        - 用户只看到"当前正文"，保存语义为覆盖写（类似 VSCode Auto Save）
        - 为防误写，默认保留最近 N 份历史备份（history/final_<timestamp>.md）

        Args:
            project_id: Project id.
            chapter: Chapter id.
            content: Draft content.
            word_count: Optional word count override.
            pending_confirmations: Optional pending confirmations for meta.
            create_prev_backup: Whether to keep history backups (best-effort).

        Returns:
            Draft meta object (version 固定为 "current").
        """
        canonical = self._canonicalize_chapter_id(chapter)
        final_path, history_dir = self._final_paths(project_id, canonical)
        payload = content or ""
        wc = int(word_count if word_count is not None else len(payload))

        if create_prev_backup and final_path.exists():
            self._rotate_draft_history(final_path, history_dir)

        try:
            await self.write_text(final_path, payload)
        except Exception:
            # If writing failed after we rotated, attempt to restore from latest backup.
            if create_prev_backup and history_dir.exists() and not final_path.exists():
                backups = sorted(
                    [p for p in history_dir.iterdir() if p.name.startswith("final_") and p.suffix == ".md"],
                    key=lambda p: p.stat().st_mtime,
                )
                if backups:
                    try:
                        os.replace(str(backups[-1]), str(final_path))
                    except OSError:
                        pass
            raise

        draft = Draft(
            chapter=canonical,
            version="current",
            content=payload,
            word_count=wc,
            pending_confirmations=pending_confirmations or [],
            created_at=datetime.now(),
        )
        meta_path = final_path.with_suffix(".meta.yaml")
        await self.write_yaml(meta_path, draft.model_dump(mode="json"))
        return draft

    async def get_chapter_tail_chunks(
        self,
        project_id: str,
        chapter: str,
        limit: int = 2,
    ) -> List[Dict[str, Any]]:
        """Return tail text chunks from the latest draft of a chapter.

        Args:
            project_id: Project id.
            chapter: Chapter id.
            limit: Number of tail chunks to return.

        Returns:
            List of tail text chunk payloads.
        """
        limit = max(int(limit or 0), 0)
        if limit <= 0:
            return []

        draft_path = self.get_latest_draft_file(project_id, chapter)
        if not draft_path or not draft_path.exists():
            return []

        try:
            text = await self.read_text(draft_path)
        except Exception:
            return []

        from app.services.text_chunk_service import text_chunk_service

        chunks = text_chunk_service.split_text_to_chunks(text)
        if not chunks:
            return []

        rel_path = draft_path.relative_to(self.get_project_path(project_id)).as_posix()
        draft_label = "final" if draft_path.name == "final.md" else draft_path.stem.replace("draft_", "")
        tail_chunks = chunks[-limit:]
        payloads = []
        for chunk in tail_chunks:
            payloads.append(
                {
                    "text": chunk.get("text"),
                    "chapter": chapter,
                    "source": {
                        "chapter": chapter,
                        "draft": draft_label,
                        "path": rel_path,
                        "paragraph": chunk.get("paragraph"),
                        "window": chunk.get("window"),
                        "start": chunk.get("start"),
                        "end": chunk.get("end"),
                        "tail": True,
                    },
                }
            )
        return payloads

    def _migrate_chapter_dir(self, project_id: str, chapter: str, canonical: str) -> None:
        drafts_dir = self.get_project_path(project_id) / "drafts"
        if not drafts_dir.exists():
            return
        source_name = self._resolve_chapter_dir_name(project_id, chapter)
        if not source_name or source_name == canonical:
            return
        source_path = drafts_dir / source_name
        target_path = drafts_dir / canonical
        if not source_path.exists() or not source_path.is_dir():
            return
        if target_path.exists():
            for item in source_path.iterdir():
                target_item = target_path / item.name
                if not target_item.exists():
                    item.rename(target_item)
            try:
                source_path.rmdir()
            except OSError:
                pass
            return
        source_path.rename(target_path)

    def _resolve_summary_path(self, project_id: str, chapter: str) -> Optional[Path]:
        summaries_dir = self.get_project_path(project_id) / "summaries"
        canonical = self._canonicalize_chapter_id(chapter)
        if summaries_dir.exists():
            canonical_path = summaries_dir / f"{canonical}_summary.yaml"
            if canonical_path.exists():
                return canonical_path
            raw_path = summaries_dir / f"{chapter}_summary.yaml"
            if raw_path.exists():
                return raw_path
            for path in summaries_dir.glob("*_summary.yaml"):
                name = path.stem.replace("_summary", "")
                if self._canonicalize_chapter_id(name) == canonical:
                    return path
        return summaries_dir / f"{canonical}_summary.yaml"

    def _migrate_summary_file(self, project_id: str, chapter: str, canonical: str) -> None:
        summaries_dir = self.get_project_path(project_id) / "summaries"
        if not summaries_dir.exists():
            return
        target_path = summaries_dir / f"{canonical}_summary.yaml"
        if target_path.exists():
            return
        source_path = self._resolve_summary_path(project_id, chapter)
        if not source_path:
            return
        if source_path.exists() and source_path != target_path:
            source_path.rename(target_path)

    async def save_scene_brief(self, project_id: str, chapter: str, brief: SceneBrief) -> None:
        """Save a scene brief."""
        canonical = self._canonicalize_chapter_id(chapter)
        self._migrate_chapter_dir(project_id, chapter, canonical)
        file_path = self.get_project_path(project_id) / "drafts" / canonical / "scene_brief.yaml"
        await self.write_yaml(file_path, brief.model_dump())

    async def get_scene_brief(self, project_id: str, chapter: str) -> Optional[SceneBrief]:
        """Get a scene brief."""
        resolved = self._resolve_chapter_dir_name(project_id, chapter)
        file_path = self.get_project_path(project_id) / "drafts" / resolved / "scene_brief.yaml"
        if not file_path.exists():
            return None
        data = await self.read_yaml(file_path)
        return SceneBrief(**data)

    async def save_draft(
        self,
        project_id: str,
        chapter: str,
        version: str,
        content: str,
        word_count: int,
        pending_confirmations: Optional[List[str]] = None,
    ) -> Draft:
        """Save a draft."""
        canonical = self._canonicalize_chapter_id(chapter)
        self._migrate_chapter_dir(project_id, chapter, canonical)
        draft = Draft(
            chapter=canonical,
            version=version,
            content=content,
            word_count=word_count,
            pending_confirmations=pending_confirmations or [],
            created_at=datetime.now(),
        )

        file_path = self.get_project_path(project_id) / "drafts" / canonical / f"draft_{version}.md"
        await self.write_text(file_path, content)

        meta_path = self.get_project_path(project_id) / "drafts" / canonical / f"draft_{version}.meta.yaml"
        await self.write_yaml(meta_path, draft.model_dump(mode="json"))

        return draft

    async def get_draft(self, project_id: str, chapter: str, version: str) -> Optional[Draft]:
        """Get a draft."""
        resolved = self._resolve_chapter_dir_name(project_id, chapter)
        canonical = self._canonicalize_chapter_id(chapter)
        file_path = self.get_project_path(project_id) / "drafts" / resolved / f"draft_{version}.md"
        if not file_path.exists():
            return None

        content = await self.read_text(file_path)
        meta_path = self.get_project_path(project_id) / "drafts" / resolved / f"draft_{version}.meta.yaml"

        if meta_path.exists():
            meta = await self.read_yaml(meta_path)
            meta["chapter"] = canonical or meta.get("chapter") or chapter
            return Draft(**meta)

        return Draft(
            chapter=canonical or chapter,
            version=version,
            content=content,
            word_count=len(content),
            pending_confirmations=[],
            created_at=datetime.now(),
        )

    async def get_latest_draft(self, project_id: str, chapter: str) -> Optional[Draft]:
        """Get the latest draft."""
        versions = await self.list_draft_versions(project_id, chapter)
        if not versions:
            return None
        latest = versions[-1]
        return await self.get_draft(project_id, chapter, latest)

    async def list_draft_versions(self, project_id: str, chapter: str) -> List[str]:
        """List draft versions for a chapter."""
        resolved = self._resolve_chapter_dir_name(project_id, chapter)
        drafts_dir = self.get_project_path(project_id) / "drafts" / resolved
        if not drafts_dir.exists():
            return []

        versions = []
        for file_path in drafts_dir.glob("draft_*.md"):
            versions.append(file_path.stem.replace("draft_", ""))

        return sorted(versions)

    async def save_review(self, project_id: str, chapter: str, review: ReviewResult) -> None:
        """Save a review result."""
        canonical = self._canonicalize_chapter_id(chapter)
        self._migrate_chapter_dir(project_id, chapter, canonical)
        file_path = self.get_project_path(project_id) / "drafts" / canonical / "review.yaml"
        await self.write_yaml(file_path, review.model_dump())

    async def get_review(self, project_id: str, chapter: str) -> Optional[ReviewResult]:
        """Get a review result."""
        resolved = self._resolve_chapter_dir_name(project_id, chapter)
        file_path = self.get_project_path(project_id) / "drafts" / resolved / "review.yaml"
        if not file_path.exists():
            return None
        data = await self.read_yaml(file_path)
        return ReviewResult(**data)

    async def save_final_draft(self, project_id: str, chapter: str, content: str) -> None:
        """Save a final draft."""
        await self.save_current_draft(
            project_id=project_id,
            chapter=chapter,
            content=content,
            create_prev_backup=True,
        )

    async def get_final_draft(self, project_id: str, chapter: str) -> Optional[str]:
        """Get a final draft."""
        resolved = self._resolve_chapter_dir_name(project_id, chapter)
        file_path = self.get_project_path(project_id) / "drafts" / resolved / "final.md"
        if file_path.exists():
            return await self.read_text(file_path)

        # Backward compatibility: migrate from legacy draft_*.md if final.md is missing.
        legacy_path = self.get_latest_draft_file(project_id, resolved)
        if not legacy_path or not legacy_path.exists() or legacy_path.name == "final.md":
            return None
        try:
            text = await self.read_text(legacy_path)
        except Exception:
            return None

        try:
            await self.save_current_draft(
                project_id=project_id,
                chapter=resolved,
                content=text,
                create_prev_backup=False,
            )
        except Exception:
            # Migration is best-effort; still return the legacy content if saving failed.
            pass
        return text

    async def save_chapter_summary(self, project_id: str, summary: ChapterSummary) -> None:
        """Save a chapter summary."""
        raw_chapter = summary.chapter
        summary.chapter = self._canonicalize_chapter_id(summary.chapter)
        summary = self._ensure_volume_id(summary)
        self._migrate_summary_file(project_id, raw_chapter, summary.chapter)
        file_path = self.get_project_path(project_id) / "summaries" / f"{summary.chapter}_summary.yaml"
        await self.write_yaml(file_path, summary.model_dump())

    async def get_chapter_summary(self, project_id: str, chapter: str) -> Optional[ChapterSummary]:
        """Get a chapter summary."""
        canonical = self._canonicalize_chapter_id(chapter)
        file_path = self._resolve_summary_path(project_id, chapter)
        if not file_path.exists():
            return None
        data = await self.read_yaml(file_path)
        summary = ChapterSummary(**data)
        summary.chapter = canonical or summary.chapter
        return self._ensure_volume_id(summary)

    async def list_chapter_summaries(
        self,
        project_id: str,
        volume_id: Optional[str] = None,
    ) -> List[ChapterSummary]:
        """List chapter summaries."""
        summaries_dir = self.get_project_path(project_id) / "summaries"
        if not summaries_dir.exists():
            return []

        summaries: Dict[str, ChapterSummary] = {}
        summary_mtime: Dict[str, float] = {}
        for file_path in summaries_dir.glob("*_summary.yaml"):
            try:
                data = await self.read_yaml(file_path)
                summary = ChapterSummary(**data)
                summary.chapter = self._canonicalize_chapter_id(summary.chapter or file_path.stem.replace("_summary", ""))
                summary = self._ensure_volume_id(summary)
                if volume_id and summary.volume_id != volume_id:
                    continue
                chapter_id = summary.chapter
                current_mtime = file_path.stat().st_mtime
                if chapter_id not in summaries or current_mtime > summary_mtime.get(chapter_id, 0):
                    summaries[chapter_id] = summary
                    summary_mtime[chapter_id] = current_mtime
            except Exception:
                continue

        def summary_sort_key(summary: ChapterSummary):
            vol_weight = self._volume_sort_weight(summary.volume_id)
            order_weight = summary.order_index if isinstance(summary.order_index, int) else 10**9
            chapter_weight = ChapterIDValidator.calculate_weight(summary.chapter)
            return (vol_weight, order_weight, chapter_weight)

        ordered = sorted(summaries.values(), key=summary_sort_key)
        return ordered

    async def list_chapters(self, project_id: str) -> List[str]:
        """List chapters for a project."""
        drafts_dir = self.get_project_path(project_id) / "drafts"
        if not drafts_dir.exists():
            return []

        chapters = []
        seen = set()
        for path in drafts_dir.iterdir():
            if not path.is_dir():
                continue
            canonical = self._canonicalize_chapter_id(path.name)
            if not canonical or canonical in seen:
                continue
            seen.add(canonical)
            chapters.append(canonical)
        # If user has customized chapter order (via ChapterSummary.order_index),
        # we respect it; otherwise fallback to chapter id weight ordering.
        try:
            summaries = await self.list_chapter_summaries(project_id)
        except Exception:
            summaries = []

        summary_map: Dict[str, ChapterSummary] = {}
        for s in summaries:
            if s and s.chapter:
                summary_map[self._canonicalize_chapter_id(s.chapter)] = s

        def chapter_sort_key(chapter_id: str):
            summary = summary_map.get(chapter_id)
            vol_id = (summary.volume_id if summary else None) or (ChapterIDValidator.extract_volume_id(chapter_id) or "V1")
            vol_weight = self._volume_sort_weight(vol_id)
            order_weight = summary.order_index if summary and isinstance(summary.order_index, int) else 10**9
            chapter_weight = ChapterIDValidator.calculate_weight(chapter_id)
            return (vol_weight, order_weight, chapter_weight)

        return sorted(chapters, key=chapter_sort_key)

    async def delete_chapter(self, project_id: str, chapter: str) -> bool:
        """Delete all draft artifacts for a chapter."""
        project_path = self.get_project_path(project_id)
        canonical = self._canonicalize_chapter_id(chapter)
        deleted_any = False
        drafts_dir = project_path / "drafts"
        if drafts_dir.exists():
            for path in drafts_dir.iterdir():
                if path.is_dir() and self._canonicalize_chapter_id(path.name) == canonical:
                    shutil.rmtree(path)
                    deleted_any = True

        summaries_dir = project_path / "summaries"
        if summaries_dir.exists():
            for path in summaries_dir.glob("*_summary.yaml"):
                name = path.stem.replace("_summary", "")
                if self._canonicalize_chapter_id(name) == canonical:
                    path.unlink()
                    deleted_any = True

        return deleted_any

    async def get_context_for_writing(self, project_id: str, current_chapter: str) -> Dict[str, Any]:
        """Get structured context for writing."""
        return await self.context_retriever.retrieve_context(project_id, current_chapter)

    async def list_volume_summaries(self, project_id: str) -> List[VolumeSummary]:
        """List volume summaries."""
        summaries: List[VolumeSummary] = []
        volumes = await self.volume_storage.list_volumes(project_id)
        for volume in volumes:
            summary = await self.volume_storage.get_volume_summary(project_id, volume.id)
            if summary:
                summaries.append(summary)
        return summaries

    async def search_text_chunks(
        self,
        project_id: str,
        query: str,
        limit: int = 8,
        queries: Optional[List[str]] = None,
        chapters: Optional[List[str]] = None,
        exclude_chapters: Optional[List[str]] = None,
        rebuild: bool = False,
        semantic_rerank: bool = False,
        rerank_query: Optional[str] = None,
        rerank_top_k: int = 16,
    ) -> List[Dict[str, Any]]:
        """Search indexed text chunks for a query.

        Args:
            project_id: Project id.
            query: Query string.
            limit: Max results.
            chapters: Chapter whitelist.
            exclude_chapters: Chapter blacklist.
            rebuild: Force rebuild index.

        Returns:
            Ranked text chunk hits.
        """
        from app.services.text_chunk_service import text_chunk_service
        return await text_chunk_service.search(
            project_id=project_id,
            query=query,
            limit=limit,
            queries=queries,
            chapters=chapters,
            exclude_chapters=exclude_chapters,
            rebuild=rebuild,
            semantic_rerank=semantic_rerank,
            rerank_query=rerank_query,
            rerank_top_k=rerank_top_k,
        )

    async def rebuild_text_chunk_index(self, project_id: str) -> Dict[str, Any]:
        """Force rebuild of text chunk index.

        Args:
            project_id: Project id.

        Returns:
            Index metadata.
        """
        from app.services.text_chunk_service import text_chunk_service
        meta = await text_chunk_service.build_index(project_id, force=True)
        return meta.model_dump(mode="json")

    async def save_conflict_report(self, project_id: str, chapter: str, report: Dict[str, Any]) -> None:
        """Save a conflict report."""
        canonical = self._canonicalize_chapter_id(chapter)
        self._migrate_chapter_dir(project_id, chapter, canonical)
        file_path = self.get_project_path(project_id) / "drafts" / canonical / "conflicts.yaml"
        await self.write_yaml(file_path, report)

    def _ensure_volume_id(self, summary: ChapterSummary) -> ChapterSummary:
        """Ensure volume_id is set on a summary."""
        if not summary.volume_id:
            summary.volume_id = ChapterIDValidator.extract_volume_id(summary.chapter) or "V1"
        return summary

    def _volume_sort_weight(self, volume_id: Optional[str]) -> int:
        """Sort helper for volume ids like V1, V2..."""
        raw = str(volume_id or "").strip().upper()
        if raw.startswith("V"):
            try:
                return int(raw[1:])
            except Exception:
                return 0
        return 0

    async def reorder_chapters(self, project_id: str, volume_id: str, chapter_order: List[str]) -> List[ChapterSummary]:
        """
        Persist chapter order within a volume by writing ChapterSummary.order_index.

        Args:
            project_id: Project id.
            volume_id: Target volume id (e.g., V1).
            chapter_order: Ordered chapter ids (canonical).

        Returns:
            Updated summaries for chapters in the provided order.
        """
        canonical_volume = (str(volume_id or "").strip().upper() or "V1")
        chapter_order = [self._canonicalize_chapter_id(ch) for ch in (chapter_order or []) if str(ch or "").strip()]
        if not chapter_order:
            return []

        existing_chapters = set(await self.list_chapters(project_id))
        for ch in chapter_order:
            if ch not in existing_chapters:
                raise ValueError(f"章节不存在：{ch}")
            inferred_volume = ChapterIDValidator.extract_volume_id(ch) or "V1"
            if str(inferred_volume).strip().upper() != canonical_volume:
                raise ValueError(f"章节 {ch} 不属于分卷 {canonical_volume}")

        updated: List[ChapterSummary] = []
        for idx, chapter_id in enumerate(chapter_order, start=1):
            summary = await self.get_chapter_summary(project_id, chapter_id)
            if not summary:
                summary = ChapterSummary(chapter=chapter_id, volume_id=canonical_volume, title="", word_count=0)
            summary.chapter = self._canonicalize_chapter_id(summary.chapter)
            summary.volume_id = canonical_volume
            summary.order_index = idx
            await self.save_chapter_summary(project_id, summary)
            updated.append(summary)
        return updated
